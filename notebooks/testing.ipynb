{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the first argument must be callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-b51123f74271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mmeta_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/nmnt/media/home/alex_samoylenko/Federated/FederatedUNet/FederatedUNet/dataset/metas/meta_philips-F.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m dataset = cache_methods(FederatedDataset_dpipe(meta_path),\n\u001b[0;32m---> 50\u001b[0;31m                         methods=['load_x', 'load_y', 'len'])\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# n_samples_per_epoch = 20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/dpipe/dataset/wrappers.py\u001b[0m in \u001b[0;36mcache_methods\u001b[0;34m(instance, methods, maxsize)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mnew_methods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cached'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mProxy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_methods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/dpipe/dataset/wrappers.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mnew_methods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cached'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mProxy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_methods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mdecorating_function\u001b[0;34m(user_function)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorating_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lru_cache_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_CacheInfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: the first argument must be callable"
     ]
    }
   ],
   "source": [
    "from dpipe.dataset import CSV\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from dpipe.dataset.wrappers import cache_methods\n",
    "from dpipe.batch_iter import Infinite, load_by_random_id\n",
    "from dpipe.batch_iter.utils import unpack_args\n",
    "from dpipe.medim.visualize import slice3d\n",
    "\n",
    "class FederatedDataset_dpipe(CSV):\n",
    "    def __init__(self, meta_path, image_path = '/nmnt/x3-hdd/data/DA/CC359/originalScaled',\n",
    "                 target_path='/nmnt/x3-hdd/data/DA/CC359/Silver-standard-MLScaled', \n",
    "                 img_col='img', target_col='target', index_col = 'id'):\n",
    "        '''\n",
    "        :param class_name: one of ['siemens-M', 'siemens-F', 'ge-M', 'ge-F', 'philips-M', 'philips-F']\n",
    "        '''\n",
    "        self.image_path = image_path\n",
    "        self.target_path = target_path\n",
    "        self.meta_path = meta_path\n",
    "        self.img_col = img_col\n",
    "        self.target_col = target_col\n",
    "        self.df_meta = pd.read_csv(meta_path)\n",
    "        self.ids = self.df_meta[index_col]\n",
    "        self.len = self.df_meta.shape[0]\n",
    "    def load_x(self, _id):\n",
    "        img = np.load(os.path.join(self.image_path, self.df_meta.iloc[_id][self.img_col]))\n",
    "        img = np.clip(img, -1000, None)\n",
    "        img = cv2.resize(img, (256, 170))\n",
    "        return img.astype(np.float32)\n",
    "    def load_y(self, _id):\n",
    "        target = np.load(os.path.join(self.target_path, self.df_meta.iloc[_id][self.target_col]))\n",
    "        return target.astype(np.float32)\n",
    "    def len(self):\n",
    "        return self.df_meta.shape[0]\n",
    "    \n",
    "def get_slice(*inputs):\n",
    "    img, target = inputs\n",
    "    # masked = ((x < 0).sum(axis=-2).sum(axis=-2) != 0)\n",
    "    # to_decide = np.nonzero(masked)[0]\n",
    "    _id = np.random.choice(img.shape[-1])\n",
    "\n",
    "    #     print(\"X: \", x[:, _id, ...].shape, _id)\n",
    "    #     print(\"M: \", m[:, _id, ...].shape, _id)\n",
    "    return [[img[..., _id]], [target[..., _id]]]   \n",
    "    \n",
    "    \n",
    "meta_path = '/nmnt/media/home/alex_samoylenko/Federated/FederatedUNet/FederatedUNet/dataset/metas/meta_philips-F.csv'\n",
    "dataset = cache_methods(FederatedDataset_dpipe(meta_path),\n",
    "                        methods=['load_x', 'load_y', 'len'])\n",
    "\n",
    "# n_samples_per_epoch = 20\n",
    "# batch_size = 2\n",
    "\n",
    "# trainloader = Infinite(\n",
    "#                 load_by_random_id(dataset.load_x, dataset.load_y, ids=dataset.ids),\n",
    "#                 unpack_args(get_slice),\n",
    "#                 batches_per_epoch=max(n_samples_per_epoch//batch_size,1), batch_size=batch_size)\n",
    "# res = []\n",
    "# for i in trainloader():\n",
    "#     res.append(i)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import cv2\n",
    "img = cv2.resize(images[1], (256, 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 256)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d7041f2ea746febbf37d1790013920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='idx', max=0), Output()), _dom_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62fc086885c4c028d9ad7d9b0bb72ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='idx', max=0), Output()), _dom_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slice3d(np.array(img[..., None]))\n",
    "slice3d(np.array(res[0][0][1][..., None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 240)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.tensor(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 170, 256])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-d3fca9fd75ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "res[0][0].to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae9c65fc51f42fc85c65b6cc3483a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='idx', max=0), Output()), _dom_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slice3d(np.array([res[0][0][0]]), np.array([res[0][1][0]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Source: error occured, setting event...\n",
      "ERROR:root:Source: event was set\n",
      "Exception in thread Thread-46:\n",
      "Traceback (most recent call last):\n",
      "  File \"/nmnt/media/home/alex_samoylenko/miniconda3/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/nmnt/media/home/alex_samoylenko/miniconda3/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/nmnt/media/home/alex_samoylenko/miniconda3/lib/python3.7/site-packages/pdp/base.py\", line 120, in target\n",
      "    for value in iterable:\n",
      "  File \"/nmnt/media/home/alex_samoylenko/miniconda3/lib/python3.7/site-packages/dpipe/batch_iter/sources.py\", line 47, in load_by_random_id\n",
      "    yield squeeze_first(tuple(pam(loaders, id_)))\n",
      "  File \"/nmnt/media/home/alex_samoylenko/miniconda3/lib/python3.7/site-packages/dpipe/medim/itertools.py\", line 27, in pam\n",
      "    yield f(*args, **kwargs)\n",
      "  File \"<ipython-input-14-97f5f9fcdc71>\", line 24, in load_x\n",
      "    img = np.clip(img, -1000)\n",
      "  File \"<__array_function__ internals>\", line 4, in clip\n",
      "TypeError: _clip_dispatcher() missing 1 required positional argument: 'a_max'\n",
      "\n"
     ]
    },
    {
     "ename": "StopEvent",
     "evalue": "pdp: Error in the tread or process was detected, check output for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopEvent\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0d4b74743519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pdp/pipeline.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pipeline was exhausted, all workers were stopped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopEvent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pdp: Error in the tread or process was detected, check output for details.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopEvent\u001b[0m: pdp: Error in the tread or process was detected, check output for details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.7964e-34, -4.6407e-33, -6.3732e-34,  ...,  1.3102e-24,\n",
       "            1.8588e-25, -1.2037e-26],\n",
       "          [ 2.1663e-34, -4.9942e-33,  6.1950e-33,  ...,  5.3831e-25,\n",
       "            3.1685e-25,  2.3260e-26],\n",
       "          [ 1.2967e-33,  1.2960e-33, -1.5742e-32,  ..., -3.1757e-24,\n",
       "            2.8754e-25,  9.0239e-25],\n",
       "          ...,\n",
       "          [ 6.9637e-37, -2.0780e-37,  7.8281e-37,  ..., -3.7896e-33,\n",
       "           -1.5403e-33, -1.1136e-33],\n",
       "          [ 1.8540e-37, -1.5937e-36, -6.8164e-36,  ...,  3.9279e-34,\n",
       "            1.3196e-34, -4.4222e-34],\n",
       "          [ 1.2300e-37, -1.5539e-36, -3.2819e-36,  ..., -5.2589e-34,\n",
       "           -1.2237e-34, -3.5586e-34]]],\n",
       "\n",
       "\n",
       "        [[[ 5.5316e-36,  1.4156e-29, -1.1910e-28,  ..., -0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 6.5618e-36, -7.6500e-30,  6.4365e-29,  ..., -0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 1.4254e-35, -3.5786e-30,  3.0110e-29,  ...,  0.0000e+00,\n",
       "           -0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [-8.4078e-45,  8.1027e-32, -6.8174e-31,  ...,  0.0000e+00,\n",
       "           -0.0000e+00,  0.0000e+00],\n",
       "          [-1.4013e-45,  1.4801e-31, -1.2453e-30,  ...,  0.0000e+00,\n",
       "           -0.0000e+00,  0.0000e+00],\n",
       "          [-0.0000e+00, -9.9805e-33,  8.3973e-32,  ...,  0.0000e+00,\n",
       "           -0.0000e+00,  0.0000e+00]]]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(images).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, and uint8.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-798739d38c4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, and uint8."
     ]
    }
   ],
   "source": [
    "torch.tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
